# GoodNotes-AI (study_kb) ‚ú®

–°—Ç—ç–Ω–¥—ç–ª–æ–Ω-–ø–∞–ø–∫–∞ –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏ –º–∞–∫–µ—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –∏ –æ–±—É—á–µ–Ω–∏—è YOLO.

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

- [–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–∫–∏ üóÇÔ∏è](#—Å—Ç—Ä—É–∫—Ç—É—Ä–∞-–ø–∞–ø–∫–∏-Ô∏è)
- [–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è üì¶](#—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è-)
- [–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç –¥–ª—è –∫–æ–ª–ª–µ–≥–∏ üöÄ](#–±—ã—Å—Ç—Ä—ã–π-—Å—Ç–∞—Ä—Ç-–¥–ª—è-–∫–æ–ª–ª–µ–≥–∏-)
- [–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤ VS Code / Cursor üß∞](#–Ω–∞—Å—Ç—Ä–æ–π–∫–∞-–≤-vs-code--cursor-)
- [–ü—Ä–æ—Ü–µ—Å—Å —Ä–∞–∑–º–µ—Ç–∫–∏ ‚úçÔ∏è](#annotator-workflow-details)
- [–û–±—É—á–µ–Ω–∏–µ (owner) üß™](#owner-workflow-training)
- [–ó–∞–º–µ—Ç–∫–∏ üß†](#notes)

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–∫–∏ üóÇÔ∏è

- data/ ‚Äî place source PDFs here (subfolders allowed)
- dataset/
  - images/ ‚Äî rendered pages for annotated samples
  - viz/ ‚Äî previews with bounding boxes for QA
  - annotations.json ‚Äî labels with metadata
  - yolo_iter/ ‚Äî auto-generated YOLO export (ignored in git)
- markup.ipynb ‚Äî interactive annotation tool
- iterative_learning.ipynb ‚Äî YOLO training/evaluation
- MARKUP_INSTRUCTION.md ‚Äî labeling guide
- requirements.txt ‚Äî dependencies

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è üì¶

Tested with Python 3.10+.

Runtime deps for `markup.ipynb` are present in `requirements.txt`:

- PyMuPDF (`pymupdf`), OpenCV (`opencv-python-headless`), Pillow, numpy, matplotlib
- Jupyter + widgets: `notebook`, `ipykernel`, `ipython`, `ipywidgets`, `ipympl`
- Training/extra: `ultralytics`, `torch`, `torchvision`, `pycocotools`, etc.

Enable Git LFS once on your machine:

- `git lfs install` (PDFs are tracked via `.gitattributes`)

### –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç –¥–ª—è –∫–æ–ª–ª–µ–≥–∏ üöÄ

```bash
# 1) Get the repo and create a venv
git clone <repo-url>
cd study_kb
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\\Scripts\\activate

# 2) Install deps
pip install -r requirements.txt

# 3) Add PDFs to annotate (subfolders allowed)
mkdir -p data
# put your PDFs into data/

# 4) Start annotating
jupyter notebook markup.ipynb  # or open the notebook in VS Code
# In the UI: Rescan PDFs -> pick PDF -> set Page -> Load -> draw -> Save

# 5) Commit and push your annotations
git add dataset_new/images dataset_new/viz dataset_new/annotations.json data
git commit -m "annot: +N pages (<name>)"
git push
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤ VS Code / Cursor üß∞

1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—â—ë –Ω–µ —Å—Ç–æ—è—Ç):
   - Python (Microsoft)
   - Jupyter (Microsoft)
2. –û—Ç–∫—Ä–æ–π—Ç–µ –ø–∞–ø–∫—É `study_kb` –≤ VS Code –∏–ª–∏ Cursor (File ‚Üí Open Folder...).
3. –°–æ–∑–¥–∞–π—Ç–µ –∏ –∞–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Windows: .venv\Scripts\activate
   pip install -r requirements.txt
   ```
4. –í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä Python –≤ VS Code/Cursor:
   - –ö–æ–º–∞–Ω–¥–∞: ‚ÄúPython: Select Interpreter‚Äù ‚Üí –≤—ã–±–µ—Ä–∏—Ç–µ `.venv`.
5. –ü–æ—Å—Ç–∞–≤—å—Ç–µ —è–¥—Ä–æ Jupyter –¥–ª—è —ç—Ç–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π):
   ```bash
   python -m ipykernel install --user --name study_kb
   ```
6. –û—Ç–∫—Ä–æ–π—Ç–µ `markup.ipynb`:
   - –í –ø—Ä–∞–≤–æ–º –≤–µ—Ä—Ö–Ω–µ–º —É–≥–ª—É –Ω–æ—É—Ç–±—É–∫–∞ –≤—ã–±–µ—Ä–∏—Ç–µ Kernel ‚Üí `study_kb` (–∏–ª–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä –∏–∑ `.venv`).
   - –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–µ—Ä—Ö–Ω—è—è —è—á–µ–π–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç `%matplotlib widget` (–¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ canvas) ‚Äî —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ.
7. –ï—Å–ª–∏ –≤–∏–¥–∂–µ—Ç—ã –Ω–µ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è:
   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã `ipywidgets` –∏ `ipympl` (—Å—Ç–∞–≤—è—Ç—Å—è –∏–∑ `requirements.txt`).
   - –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ Kernel (Kernel ‚Üí Restart Kernel) –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≤—Å–µ —è—á–µ–π–∫–∏ –∑–∞–Ω–æ–≤–æ.

### Annotator workflow (details)

1. Open `markup.ipynb`.
2. Click "Rescan PDFs" if you just added files into `data/`.
3. Select a PDF, set page index, press "Load".
4. Draw boxes (left-drag), choose Class, optionally use "Propose+Add".
5. Press "Save".
6. The tool writes (repo-relative paths):
   - `dataset/images/<Dir>__<Pdf>__p<idx>.png`
   - `dataset/viz/<same>.png` (colored boxes + labels)
   - `dataset/annotations.json` with fields:
     - `image`, `width`, `height`, `source_pdf`, `page_idx`, `annotations[{bbox, category_id}]`

### Owner workflow (training)

1. Open `iterative_learning.ipynb`.
2. Export YOLO, train, evaluate.
3. Runs/logs remain local (ignored by git).

### Notes

- Document-level split prevents leakage across pages of the same PDF.
- Unique image names: `<Dir>__<Pdf>__p<idx>.png`.
- See `MARKUP_INSTRUCTION.md` for the 6-class taxonomy and edge cases.
